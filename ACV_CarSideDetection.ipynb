{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ACV_CarSideDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srdl65s0L4pb"
      },
      "source": [
        "**Use Tensorflow version 1 for using coreml tools**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDjsSeniy6-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b1a23a-3f44-463e-b6e4-82d13d5b1304"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzY6Sfb-MIJ9"
      },
      "source": [
        "**Import required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGfHHkuDzJJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9c0d6da-7215-4ca8-ae21-371e8757b920"
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D,  add, AveragePooling2D, \\\n",
        "    Activation, MaxPool2D, Flatten, Dropout,BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adamax\n",
        "import os,math\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_2tK0O_OFgr"
      },
      "source": [
        "**Mount Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcX7MvIWDTt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ee11ea-7640-43ba-d0e1-65a0aaf2c650"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhl7SBe7TOnE"
      },
      "source": [
        "**Define hyper-parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAYd6c4I612O"
      },
      "source": [
        "#training data and validation data directories\n",
        "train_data_dir = \"gdrive/My Drive/ACV Project/train\"\n",
        "validation_data_dir = \"gdrive/My Drive/ACV Project/test\"\n",
        "\n",
        "#Path to save training and best model weights\n",
        "path_train = \"gdrive/My Drive/ACV Project/modelWeights/ACV_train.h5\"\n",
        "path_best = \"gdrive/My Drive/ACV Project/modelWeights/ACV_best.h5\"\n",
        "\n",
        "#path to save coreml models\n",
        "path_coreML = \"gdrive/My Drive/ACV Project/modelWeights/resnet_train_15.mlmodel\"\n",
        "path_classLabels = \"gdrive/My Drive/ACV Project/modelWeights/labl.txt\"\n",
        "\n",
        "batch_size=16\n",
        "image_size = (224, 224)\n",
        "nb_epoch = 1000\n",
        "\n",
        "#8 output classes corresponding to 8 sides of the car\n",
        "NUMBER_OF_CLASSES = 8"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VigJjxM4fgqY"
      },
      "source": [
        "**Build Resnet34 like model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHSJJYlsXiyk"
      },
      "source": [
        "Helper function to build skip connections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHL2v3RlXvV5"
      },
      "source": [
        "def resnetBuilder(l, filters):\r\n",
        "    x = l\r\n",
        "\r\n",
        "    #Add 2 new layers\r\n",
        "    l = Conv2D(filters=filters, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(0.001))(l)\r\n",
        "    l = Conv2D(filters=filters, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(0.001))(l)\r\n",
        "    l = BatchNormalization()(l)\r\n",
        "    l = Dropout(0.5)(l)\r\n",
        "\r\n",
        "    #Add the initial input to form skip connections\r\n",
        "    x = Conv2D(filters=filters, kernel_size=(1,1), padding='same', activation='relu', kernel_regularizer=l2(0.001))(x)\r\n",
        "    x = add([x,l])\r\n",
        "    x = Activation('relu')(x)\r\n",
        "\r\n",
        "    return x "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZt8sXaRfyz_"
      },
      "source": [
        "Main module for creating Resnet34 like model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itZHgWxxf3nf"
      },
      "source": [
        "def createResnetModel():\r\n",
        "    #Input is RGB image of size 224x224\r\n",
        "    input = Input(shape=(224, 224, 3))\r\n",
        "    l = Conv2D(filters=64, kernel_size=(7,7), padding=\"same\")(input)\r\n",
        "    l = Activation('relu')(l)\r\n",
        "    l = MaxPool2D(pool_size=(3,3))(l)\r\n",
        "\r\n",
        "    #Use helper function to build model\r\n",
        "    l = resnetBuilder(l, 64)\r\n",
        "    l = resnetBuilder(l, 64)\r\n",
        "    l = resnetBuilder(l, 64)\r\n",
        "    l = resnetBuilder(l, 128)\r\n",
        "    l = resnetBuilder(l, 128)\r\n",
        "    l = resnetBuilder(l, 128)\r\n",
        "    l = resnetBuilder(l, 128)\r\n",
        "    l = resnetBuilder(l, 256)\r\n",
        "    l = resnetBuilder(l, 256)\r\n",
        "    l = resnetBuilder(l, 256)\r\n",
        "    l = resnetBuilder(l, 256)    \r\n",
        "    l = resnetBuilder(l, 256)\r\n",
        "    l = resnetBuilder(l, 256)\r\n",
        "    l = resnetBuilder(l, 512)\r\n",
        "    l = resnetBuilder(l, 512)\r\n",
        "    l = resnetBuilder(l, 512)\r\n",
        "\r\n",
        "    #AveragePooling and Flatten followed by output layer\r\n",
        "    l = AveragePooling2D(pool_size=(8,8))(l)\r\n",
        "    l = Flatten()(l)\r\n",
        "    output = Dense(NUMBER_OF_CLASSES, activation='softmax')(l)\r\n",
        "\r\n",
        "    model = Model(inputs=input, outputs=output)\r\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4BLUieJgiRS"
      },
      "source": [
        "**Compile the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgk4u09QgqJV"
      },
      "source": [
        "def compile_model(compiledModel):\r\n",
        "    compiledModel.compile(loss=categorical_crossentropy,\r\n",
        "                  optimizer=Adamax(learning_rate=0.0001, decay=1e-06),\r\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMeXTmH4hOZE"
      },
      "source": [
        "**Create callback functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6JfGT0phTj8"
      },
      "source": [
        "checkpoint = ModelCheckpoint(path_train, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto',period=1)\r\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=200, verbose=1, mode='auto')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QHW8UlehmdM"
      },
      "source": [
        "**Method to load data and train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyjZFW9D8RtG"
      },
      "source": [
        "def modelFitGenerator(fitModel):\n",
        "    #load train and validation samples\n",
        "    num_train_samples = sum([len(files) for r, d, files in os.walk(train_data_dir)])\n",
        "    num_valid_samples = sum([len(files) for r, d, files in os.walk(validation_data_dir)])\n",
        "\n",
        "    #calculate train and validation steps\n",
        "    num_train_steps = math.floor(num_train_samples/batch_size)\n",
        "    num_valid_steps = math.floor(num_valid_samples/batch_size)\n",
        "    \n",
        "    #Code for using data augmentation. \n",
        "    #Not using any augmentation parameters currently as it degrades performance.\n",
        "    train_datagen = ImageDataGenerator( ) \n",
        "    #   rotation_range=90,      \n",
        "    #   horizontal_flip=True,    \n",
        "    #   vertical_flip=True,\n",
        "    #   zoom_range=0.4)\n",
        "\n",
        "    test_datagen = ImageDataGenerator()\n",
        "\n",
        "    #Access train and validation data for training\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "      train_data_dir,\n",
        "      target_size=image_size ,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical', shuffle=True\n",
        "    )\n",
        "    validation_generator = test_datagen.flow_from_directory(\n",
        "      validation_data_dir,\n",
        "      target_size=image_size ,\n",
        "      batch_size=batch_size,\n",
        "      class_mode='categorical', shuffle=True\n",
        "    )\n",
        "\n",
        "    #Train the model using training and validation data\n",
        "    history = fitModel.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=num_train_steps//100,#num_train_steps//1000,\n",
        "      epochs=nb_epoch,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=num_valid_steps,\n",
        "      callbacks=[checkpoint, early])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MilHGLePh5Bw"
      },
      "source": [
        "**Create Resnet34 like model and compile. Load training weights, if required. Start training the model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxcs_jee8M1I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "outputId": "599da28c-453c-4c7d-b33b-843462f228b8"
      },
      "source": [
        "model = createResnetModel()\n",
        "compile_model(model)\n",
        "model.load_weights(path_best)\n",
        "modelFitGenerator(model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100001 images belonging to 8 classes.\n",
            "Found 6825 images belonging to 8 classes.\n",
            "Epoch 1/1000\n",
            "62/62 [==============================] - 1058s 17s/step - loss: 5.4588 - accuracy: 0.9677 - val_loss: 5.4608 - val_accuracy: 0.9551\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.95511, saving model to gdrive/My Drive/ACV Project/modelWeights/ACV_train.h5\n",
            "Epoch 2/1000\n",
            "62/62 [==============================] - 432s 7s/step - loss: 5.4159 - accuracy: 0.9627 - val_loss: 5.4893 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.95511\n",
            "Epoch 3/1000\n",
            "62/62 [==============================] - 421s 7s/step - loss: 5.3404 - accuracy: 0.9708 - val_loss: 5.5454 - val_accuracy: 0.9630\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.95511 to 0.96299, saving model to gdrive/My Drive/ACV Project/modelWeights/ACV_train.h5\n",
            "Epoch 4/1000\n",
            "62/62 [==============================] - 401s 6s/step - loss: 5.2987 - accuracy: 0.9688 - val_loss: 5.1878 - val_accuracy: 0.9624\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.96299\n",
            "Epoch 5/1000\n",
            "62/62 [==============================] - 398s 6s/step - loss: 5.3299 - accuracy: 0.9607 - val_loss: 5.1867 - val_accuracy: 0.9543\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.96299\n",
            "Epoch 6/1000\n",
            "62/62 [==============================] - 393s 6s/step - loss: 5.2508 - accuracy: 0.9688 - val_loss: 5.2245 - val_accuracy: 0.9595\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.96299\n",
            "Epoch 7/1000\n",
            "61/62 [============================>.] - ETA: 4s - loss: 5.2067 - accuracy: 0.9764"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6f89452e65e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodelFitGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-d86b343ca37c>\u001b[0m in \u001b[0;36mmodelFitGenerator\u001b[0;34m(fitModel)\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_valid_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       callbacks=[checkpoint, early])\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    240\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    243\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    399\u001b[0m             outs = model.test_on_batch(x, y,\n\u001b[1;32m    400\u001b[0m                                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                                        reset_metrics=False)\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1557\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1559\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzDjVDs5ihNV"
      },
      "source": [
        "**Install Coremltools.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYyFOyAPZh5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e646c5-c26e-4bae-c139-76b924d5cb79"
      },
      "source": [
        "!pip install -U coremltools "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting coremltools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/30/32f5bce33571b00f8e43e290bb4a9561956bc7f35b96dcd48f300029b23f/coremltools-4.0-cp36-none-manylinux1_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from coremltools) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: attrs in /usr/local/lib/python3.6/dist-packages (from coremltools) (20.3.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from coremltools) (1.19.4)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from coremltools) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from coremltools) (1.15.0)\n",
            "Collecting attr\n",
            "  Downloading https://files.pythonhosted.org/packages/de/be/ddc7f84d4e087144472a38a373d3e319f51a6faf6e5fc1ae897173675f21/attr-0.3.1.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from coremltools) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: sympy in /usr/local/lib/python3.6/dist-packages (from coremltools) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from coremltools) (20.8)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->coremltools) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy->coremltools) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->coremltools) (2.4.7)\n",
            "Building wheels for collected packages: attr\n",
            "  Building wheel for attr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for attr: filename=attr-0.3.1-cp36-none-any.whl size=2459 sha256=3e1ddc953423191292f7f8bf0b108013f878d59a195cf01283a2bd2ec9abd949\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/96/9b/1f8892a707d17095b5a6eab0275da9d39e68e03a26aee2e726\n",
            "Successfully built attr\n",
            "Installing collected packages: attr, coremltools\n",
            "Successfully installed attr-0.3.1 coremltools-4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA-AjqX3iz7b"
      },
      "source": [
        "**Function to create coreMLModel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv5BA3zb8A0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f850bb6-db10-4089-98e4-8bd5195890fb"
      },
      "source": [
        "import coremltools\n",
        "\n",
        "def saveCoreMLModel(kerasModel):\n",
        "    coreml_model = coremltools.converters.keras.convert(kerasModel,\n",
        "                                                    input_names=['input'],\n",
        "                                                    output_names=['probs'],\n",
        "                                                    image_input_names='input',\n",
        "                                                    predicted_feature_name='predictedAngle',\n",
        "                                                    class_labels = path_classLabels)\n",
        "    coreml_model.save(path_coreML) \n",
        "    print('CoreML model saved')\n",
        "\n",
        "model.load_weights(path_best)\n",
        "saveCoreMLModel(model)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:scikit-learn version 0.22.2.post1 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
            "WARNING:root:TensorFlow version 1.15.2 detected. Last version known to be fully compatible is 1.15.0 .\n",
            "WARNING:root:Keras version 2.3.1 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 : input_4, <keras.engine.input_layer.InputLayer object at 0x7f57e5601518>\n",
            "1 : conv2d_148, <keras.layers.convolutional.Conv2D object at 0x7f57e5601278>\n",
            "2 : activation_52, <keras.layers.core.Activation object at 0x7f57e45aa080>\n",
            "3 : max_pooling2d_4, <keras.layers.pooling.MaxPooling2D object at 0x7f57e45aa160>\n",
            "4 : conv2d_149, <keras.layers.convolutional.Conv2D object at 0x7f57e5648518>\n",
            "5 : conv2d_149__activation__, <keras.layers.core.Activation object at 0x7f57e153b358>\n",
            "6 : conv2d_150, <keras.layers.convolutional.Conv2D object at 0x7f57e56017b8>\n",
            "7 : conv2d_150__activation__, <keras.layers.core.Activation object at 0x7f5868d860b8>\n",
            "8 : batch_normalization_49, <keras.layers.normalization.BatchNormalization object at 0x7f57e45b6518>\n",
            "9 : conv2d_151, <keras.layers.convolutional.Conv2D object at 0x7f57e45ca7f0>\n",
            "10 : conv2d_151__activation__, <keras.layers.core.Activation object at 0x7f5868cc4eb8>\n",
            "11 : add_49, <keras.layers.merge.Add object at 0x7f57e4586208>\n",
            "12 : activation_53, <keras.layers.core.Activation object at 0x7f57e4515898>\n",
            "13 : conv2d_152, <keras.layers.convolutional.Conv2D object at 0x7f57e4515128>\n",
            "14 : conv2d_152__activation__, <keras.layers.core.Activation object at 0x7f5868cc48d0>\n",
            "15 : conv2d_153, <keras.layers.convolutional.Conv2D object at 0x7f57e451c470>\n",
            "16 : conv2d_153__activation__, <keras.layers.core.Activation object at 0x7f5868cb28d0>\n",
            "17 : batch_normalization_50, <keras.layers.normalization.BatchNormalization object at 0x7f57e452a2b0>\n",
            "18 : conv2d_154, <keras.layers.convolutional.Conv2D object at 0x7f57e4544908>\n",
            "19 : conv2d_154__activation__, <keras.layers.core.Activation object at 0x7f5868cb2a20>\n",
            "20 : add_50, <keras.layers.merge.Add object at 0x7f57e44f0e80>\n",
            "21 : activation_54, <keras.layers.core.Activation object at 0x7f57e45066a0>\n",
            "22 : conv2d_155, <keras.layers.convolutional.Conv2D object at 0x7f57e4506358>\n",
            "23 : conv2d_155__activation__, <keras.layers.core.Activation object at 0x7f5413cad2b0>\n",
            "24 : conv2d_156, <keras.layers.convolutional.Conv2D object at 0x7f57e450e278>\n",
            "25 : conv2d_156__activation__, <keras.layers.core.Activation object at 0x7f5413cad240>\n",
            "26 : batch_normalization_51, <keras.layers.normalization.BatchNormalization object at 0x7f57e449d0b8>\n",
            "27 : conv2d_157, <keras.layers.convolutional.Conv2D object at 0x7f57e44b88d0>\n",
            "28 : conv2d_157__activation__, <keras.layers.core.Activation object at 0x7f5413cad278>\n",
            "29 : add_51, <keras.layers.merge.Add object at 0x7f57e4463c18>\n",
            "30 : activation_55, <keras.layers.core.Activation object at 0x7f57e4470d68>\n",
            "31 : conv2d_158, <keras.layers.convolutional.Conv2D object at 0x7f57e4477278>\n",
            "32 : conv2d_158__activation__, <keras.layers.core.Activation object at 0x7f5413cad2e8>\n",
            "33 : conv2d_159, <keras.layers.convolutional.Conv2D object at 0x7f57e4481080>\n",
            "34 : conv2d_159__activation__, <keras.layers.core.Activation object at 0x7f5413cadc88>\n",
            "35 : batch_normalization_52, <keras.layers.normalization.BatchNormalization object at 0x7f57e448c240>\n",
            "36 : conv2d_160, <keras.layers.convolutional.Conv2D object at 0x7f57e442df98>\n",
            "37 : conv2d_160__activation__, <keras.layers.core.Activation object at 0x7f5413cadcf8>\n",
            "38 : add_52, <keras.layers.merge.Add object at 0x7f57e43d4a20>\n",
            "39 : activation_56, <keras.layers.core.Activation object at 0x7f57e43e3908>\n",
            "40 : conv2d_161, <keras.layers.convolutional.Conv2D object at 0x7f57e43e96a0>\n",
            "41 : conv2d_161__activation__, <keras.layers.core.Activation object at 0x7f5413cadd30>\n",
            "42 : conv2d_162, <keras.layers.convolutional.Conv2D object at 0x7f57e43e9e48>\n",
            "43 : conv2d_162__activation__, <keras.layers.core.Activation object at 0x7f5413cadcc0>\n",
            "44 : batch_normalization_53, <keras.layers.normalization.BatchNormalization object at 0x7f57e43f8c88>\n",
            "45 : conv2d_163, <keras.layers.convolutional.Conv2D object at 0x7f57e439a4e0>\n",
            "46 : conv2d_163__activation__, <keras.layers.core.Activation object at 0x7f5413cadd68>\n",
            "47 : add_53, <keras.layers.merge.Add object at 0x7f57e43c8fd0>\n",
            "48 : activation_57, <keras.layers.core.Activation object at 0x7f57e4356b38>\n",
            "49 : conv2d_164, <keras.layers.convolutional.Conv2D object at 0x7f57e4356940>\n",
            "50 : conv2d_164__activation__, <keras.layers.core.Activation object at 0x7f5413cadda0>\n",
            "51 : conv2d_165, <keras.layers.convolutional.Conv2D object at 0x7f57e435cbe0>\n",
            "52 : conv2d_165__activation__, <keras.layers.core.Activation object at 0x7f5413caddd8>\n",
            "53 : batch_normalization_54, <keras.layers.normalization.BatchNormalization object at 0x7f57e436ba58>\n",
            "54 : conv2d_166, <keras.layers.convolutional.Conv2D object at 0x7f57e438e2b0>\n",
            "55 : conv2d_166__activation__, <keras.layers.core.Activation object at 0x7f5413cade10>\n",
            "56 : add_54, <keras.layers.merge.Add object at 0x7f57e433b7f0>\n",
            "57 : activation_58, <keras.layers.core.Activation object at 0x7f57e4349a20>\n",
            "58 : conv2d_167, <keras.layers.convolutional.Conv2D object at 0x7f57e43496d8>\n",
            "59 : conv2d_167__activation__, <keras.layers.core.Activation object at 0x7f5413cade48>\n",
            "60 : conv2d_168, <keras.layers.convolutional.Conv2D object at 0x7f57e434ea20>\n",
            "61 : conv2d_168__activation__, <keras.layers.core.Activation object at 0x7f5413cade80>\n",
            "62 : batch_normalization_55, <keras.layers.normalization.BatchNormalization object at 0x7f57e42dc860>\n",
            "63 : conv2d_169, <keras.layers.convolutional.Conv2D object at 0x7f57e42fef60>\n",
            "64 : conv2d_169__activation__, <keras.layers.core.Activation object at 0x7f5413cadeb8>\n",
            "65 : add_55, <keras.layers.merge.Add object at 0x7f57e42aa5f8>\n",
            "66 : activation_59, <keras.layers.core.Activation object at 0x7f57e42bcc50>\n",
            "67 : conv2d_170, <keras.layers.convolutional.Conv2D object at 0x7f57e42bc4e0>\n",
            "68 : conv2d_170__activation__, <keras.layers.core.Activation object at 0x7f5413cadef0>\n",
            "69 : conv2d_171, <keras.layers.convolutional.Conv2D object at 0x7f57e42c3828>\n",
            "70 : conv2d_171__activation__, <keras.layers.core.Activation object at 0x7f5413cadf28>\n",
            "71 : batch_normalization_56, <keras.layers.normalization.BatchNormalization object at 0x7f57e42d1668>\n",
            "72 : conv2d_172, <keras.layers.convolutional.Conv2D object at 0x7f57e4273cf8>\n",
            "73 : conv2d_172__activation__, <keras.layers.core.Activation object at 0x7f5413cadf60>\n",
            "74 : add_56, <keras.layers.merge.Add object at 0x7f57e42213c8>\n",
            "75 : activation_60, <keras.layers.core.Activation object at 0x7f57e422fa58>\n",
            "76 : conv2d_173, <keras.layers.convolutional.Conv2D object at 0x7f57e422f2e8>\n",
            "77 : conv2d_173__activation__, <keras.layers.core.Activation object at 0x7f5413cadf98>\n",
            "78 : conv2d_174, <keras.layers.convolutional.Conv2D object at 0x7f57e4236630>\n",
            "79 : conv2d_174__activation__, <keras.layers.core.Activation object at 0x7f5413cadfd0>\n",
            "80 : batch_normalization_57, <keras.layers.normalization.BatchNormalization object at 0x7f57e4243470>\n",
            "81 : conv2d_175, <keras.layers.convolutional.Conv2D object at 0x7f57e41e5fd0>\n",
            "82 : conv2d_175__activation__, <keras.layers.core.Activation object at 0x7f5413c9df60>\n",
            "83 : add_57, <keras.layers.merge.Add object at 0x7f57e4212208>\n",
            "84 : activation_61, <keras.layers.core.Activation object at 0x7f57e41a2860>\n",
            "85 : conv2d_176, <keras.layers.convolutional.Conv2D object at 0x7f57e41a20f0>\n",
            "86 : conv2d_176__activation__, <keras.layers.core.Activation object at 0x7f5413c9df98>\n",
            "87 : conv2d_177, <keras.layers.convolutional.Conv2D object at 0x7f57e41a7438>\n",
            "88 : conv2d_177__activation__, <keras.layers.core.Activation object at 0x7f5413c9dfd0>\n",
            "89 : batch_normalization_58, <keras.layers.normalization.BatchNormalization object at 0x7f57e41b5278>\n",
            "90 : conv2d_178, <keras.layers.convolutional.Conv2D object at 0x7f57e416d828>\n",
            "91 : conv2d_178__activation__, <keras.layers.core.Activation object at 0x7f5413c9deb8>\n",
            "92 : add_58, <keras.layers.merge.Add object at 0x7f57e417fe10>\n",
            "93 : activation_62, <keras.layers.core.Activation object at 0x7f57e4192438>\n",
            "94 : conv2d_179, <keras.layers.convolutional.Conv2D object at 0x7f57e4192668>\n",
            "95 : conv2d_179__activation__, <keras.layers.core.Activation object at 0x7f5413c9de48>\n",
            "96 : conv2d_180, <keras.layers.convolutional.Conv2D object at 0x7f57e411a240>\n",
            "97 : conv2d_180__activation__, <keras.layers.core.Activation object at 0x7f5413c9ddd8>\n",
            "98 : batch_normalization_59, <keras.layers.normalization.BatchNormalization object at 0x7f57e4128080>\n",
            "99 : conv2d_181, <keras.layers.convolutional.Conv2D object at 0x7f57e4143898>\n",
            "100 : conv2d_181__activation__, <keras.layers.core.Activation object at 0x7f5413c9dd68>\n",
            "101 : add_59, <keras.layers.merge.Add object at 0x7f57e40f3ba8>\n",
            "102 : activation_63, <keras.layers.core.Activation object at 0x7f57e4102d30>\n",
            "103 : conv2d_182, <keras.layers.convolutional.Conv2D object at 0x7f57e4108240>\n",
            "104 : conv2d_182__activation__, <keras.layers.core.Activation object at 0x7f5413c9dcf8>\n",
            "105 : conv2d_183, <keras.layers.convolutional.Conv2D object at 0x7f57e410e048>\n",
            "106 : conv2d_183__activation__, <keras.layers.core.Activation object at 0x7f5413c9dd30>\n",
            "107 : batch_normalization_60, <keras.layers.normalization.BatchNormalization object at 0x7f57e409d0b8>\n",
            "108 : conv2d_184, <keras.layers.convolutional.Conv2D object at 0x7f57e40b6ef0>\n",
            "109 : conv2d_184__activation__, <keras.layers.core.Activation object at 0x7f5413c9dc18>\n",
            "110 : add_60, <keras.layers.merge.Add object at 0x7f57e40639e8>\n",
            "111 : activation_64, <keras.layers.core.Activation object at 0x7f57e40748d0>\n",
            "112 : conv2d_185, <keras.layers.convolutional.Conv2D object at 0x7f57e4079668>\n",
            "113 : conv2d_185__activation__, <keras.layers.core.Activation object at 0x7f5413c9dc50>\n",
            "114 : conv2d_186, <keras.layers.convolutional.Conv2D object at 0x7f57e4079e10>\n",
            "115 : conv2d_186__activation__, <keras.layers.core.Activation object at 0x7f5413c9db38>\n",
            "116 : batch_normalization_61, <keras.layers.normalization.BatchNormalization object at 0x7f57e4086c50>\n",
            "117 : conv2d_187, <keras.layers.convolutional.Conv2D object at 0x7f57e40284a8>\n",
            "118 : conv2d_187__activation__, <keras.layers.core.Activation object at 0x7f5413c9db70>\n",
            "119 : add_61, <keras.layers.merge.Add object at 0x7f57e3fd6f98>\n",
            "120 : activation_65, <keras.layers.core.Activation object at 0x7f57e3fe5b38>\n",
            "121 : conv2d_188, <keras.layers.convolutional.Conv2D object at 0x7f57e3fe5940>\n",
            "122 : conv2d_188__activation__, <keras.layers.core.Activation object at 0x7f5413c9da58>\n",
            "123 : conv2d_189, <keras.layers.convolutional.Conv2D object at 0x7f57e3febc18>\n",
            "124 : conv2d_189__activation__, <keras.layers.core.Activation object at 0x7f5413c9d9e8>\n",
            "125 : batch_normalization_62, <keras.layers.normalization.BatchNormalization object at 0x7f57e3ffaa58>\n",
            "126 : conv2d_190, <keras.layers.convolutional.Conv2D object at 0x7f57e3f9c2b0>\n",
            "127 : conv2d_190__activation__, <keras.layers.core.Activation object at 0x7f5413c9d898>\n",
            "128 : add_62, <keras.layers.merge.Add object at 0x7f57e3fc87f0>\n",
            "129 : activation_66, <keras.layers.core.Activation object at 0x7f57e3f58ac8>\n",
            "130 : conv2d_191, <keras.layers.convolutional.Conv2D object at 0x7f57e3f586d8>\n",
            "131 : conv2d_191__activation__, <keras.layers.core.Activation object at 0x7f5413c9d978>\n",
            "132 : conv2d_192, <keras.layers.convolutional.Conv2D object at 0x7f57e3f5da20>\n",
            "133 : conv2d_192__activation__, <keras.layers.core.Activation object at 0x7f5413c9d828>\n",
            "134 : batch_normalization_63, <keras.layers.normalization.BatchNormalization object at 0x7f57e3f6d860>\n",
            "135 : conv2d_193, <keras.layers.convolutional.Conv2D object at 0x7f57e3f8ff60>\n",
            "136 : conv2d_193__activation__, <keras.layers.core.Activation object at 0x7f5413c9d9b0>\n",
            "137 : add_63, <keras.layers.merge.Add object at 0x7f57e3f3e5f8>\n",
            "138 : activation_67, <keras.layers.core.Activation object at 0x7f57e3f4ba58>\n",
            "139 : conv2d_194, <keras.layers.convolutional.Conv2D object at 0x7f57e3f4b4a8>\n",
            "140 : conv2d_194__activation__, <keras.layers.core.Activation object at 0x7f5413c9d7f0>\n",
            "141 : conv2d_195, <keras.layers.convolutional.Conv2D object at 0x7f57e3f50828>\n",
            "142 : conv2d_195__activation__, <keras.layers.core.Activation object at 0x7f5413c9d940>\n",
            "143 : batch_normalization_64, <keras.layers.normalization.BatchNormalization object at 0x7f57e3ee0668>\n",
            "144 : conv2d_196, <keras.layers.convolutional.Conv2D object at 0x7f57e3f02cf8>\n",
            "145 : conv2d_196__activation__, <keras.layers.core.Activation object at 0x7f5413c9d860>\n",
            "146 : add_64, <keras.layers.merge.Add object at 0x7f57e2a7f630>\n",
            "147 : activation_68, <keras.layers.core.Activation object at 0x7f57e297f748>\n",
            "148 : average_pooling2d_4, <keras.layers.pooling.AveragePooling2D object at 0x7f57e297f978>\n",
            "149 : flatten_4, <keras.layers.core.Flatten object at 0x7f57e2a2b780>\n",
            "150 : dense_4, <keras.layers.core.Dense object at 0x7f57e2978160>\n",
            "151 : dense_4__activation__, <keras.layers.core.Activation object at 0x7f5413c9def0>\n",
            "CoreML model saved\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}